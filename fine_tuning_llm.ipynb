{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning an LLM on BiText dataset\n",
    "Dataset- https://huggingface.co/datasets/bitext/Bitext-customer-support-llm-chatbot-training-dataset\n",
    "\n",
    "The dataset has the following specs:\n",
    "\n",
    "Use Case: Intent Detection\n",
    "Vertical: Customer Service\n",
    "27 intents assigned to 10 categories\n",
    "26872 question/answer pairs, around 1000 per intent\n",
    "30 entity/slot types\n",
    "12 different types of language generation tags\n",
    "The categories and intents have been selected from Bitext's collection of 20 vertical-specific datasets, covering the intents that are common across all 20 verticals. The verticals are:\n",
    "\n",
    "Automotive, Retail Banking, Education, Events & Ticketing, Field Services, Healthcare, Hospitality, Insurance, Legal Services, Manufacturing, Media Streaming, Mortgages & Loans, Moving & Storage, Real Estate/Construction, Restaurant & Bar Chains, Retail/E-commerce, Telecommunications, Travel, Utilities, Wealth Management\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\imaad\\anaconda3\\envs\\healthenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"bitext/Bitext-customer-support-llm-chatbot-training-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['flags', 'instruction', 'category', 'intent', 'response'],\n",
       "        num_rows: 26872\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring Data for BERT QA\n",
    "- Context: The instructions (or broader conversation, if available) can act as the context for the model. Since we don't have broader conversational context, you can use just the instruction as the question in this case.\n",
    "- Question: Extract from instruction.\n",
    "- Answer: Taken directly from the response.\n",
    "\n",
    "## Example Breakdown for BERT QA:\n",
    "\n",
    "Context: This will usually be general knowledge about the domain or background. Since this dataset doesn't provide a broader context, you can leave this field blank or generalize it.\n",
    "\n",
    "Example Context: \"You are interacting with a support system that helps with cancelling orders.\"\n",
    "Question: Use the instruction as the question.\n",
    "\n",
    "Example Question: \"I need help cancelling purchase {{Order Number}}.\"\n",
    "Answer: The response will be the answer the model should learn to extract from the context.\n",
    "\n",
    "Example Answer: \"To cancel your purchase, follow these steps: 1. Log into your account. 2. Locate your order. 3. Initiate the cancellation.\"\n",
    "\n",
    "\n",
    "# Full Example Format for BERT QA:\n",
    "- Data in Row Format:\n",
    "Flags: BLQ\n",
    "Instruction: \"I need help cancelling purchase {{Order Number}}.\"\n",
    "Response: \"To cancel your purchase, follow these steps: 1. Log into your account. 2. Locate your order. 3. Initiate the cancellation.\"\n",
    "- BERT QA Format:\n",
    "Context: \"You are interacting with a support system that helps with cancelling orders.\"\n",
    "Question: \"I need help cancelling purchase {{Order Number}}.\"\n",
    "Answer: \"To cancel your purchase, follow these steps: 1. Log into your account. 2. Locate your order. 3. Initiate the cancellation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flags</th>\n",
       "      <th>instruction</th>\n",
       "      <th>category</th>\n",
       "      <th>intent</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>question about cancelling order {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I've understood you have a question regarding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BQZ</td>\n",
       "      <td>i have a question about cancelling oorder {{Or...</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I've been informed that you have a question ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLQZ</td>\n",
       "      <td>i need help cancelling puchase {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I can sense that you're seeking assistance wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BL</td>\n",
       "      <td>I need to cancel purchase {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I understood that you need assistance with can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCELN</td>\n",
       "      <td>I cannot afford this order, cancel purchase {{...</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I'm sensitive to the fact that you're facing f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26867</th>\n",
       "      <td>BL</td>\n",
       "      <td>I am waiting for a rebate of {{Refund Amount}}...</td>\n",
       "      <td>REFUND</td>\n",
       "      <td>track_refund</td>\n",
       "      <td>Thank you for sharing your situation regarding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26868</th>\n",
       "      <td>BIL</td>\n",
       "      <td>how to see if there is anything wrong with my ...</td>\n",
       "      <td>REFUND</td>\n",
       "      <td>track_refund</td>\n",
       "      <td>Ensuring the accuracy of your restitution is o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26869</th>\n",
       "      <td>BLQZ</td>\n",
       "      <td>I'm waiting for a reimbjrsement of {{Currency ...</td>\n",
       "      <td>REFUND</td>\n",
       "      <td>track_refund</td>\n",
       "      <td>Firstly, I genuinely understand the importance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26870</th>\n",
       "      <td>BL</td>\n",
       "      <td>I don't know what to do to see my reimbursemen...</td>\n",
       "      <td>REFUND</td>\n",
       "      <td>track_refund</td>\n",
       "      <td>I've understood you're unsure about how to che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26871</th>\n",
       "      <td>BL</td>\n",
       "      <td>I need to know if there is anything new on the...</td>\n",
       "      <td>REFUND</td>\n",
       "      <td>track_refund</td>\n",
       "      <td>It's completely understandable that you want t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26872 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       flags                                        instruction category  \\\n",
       "0          B   question about cancelling order {{Order Number}}    ORDER   \n",
       "1        BQZ  i have a question about cancelling oorder {{Or...    ORDER   \n",
       "2       BLQZ    i need help cancelling puchase {{Order Number}}    ORDER   \n",
       "3         BL         I need to cancel purchase {{Order Number}}    ORDER   \n",
       "4      BCELN  I cannot afford this order, cancel purchase {{...    ORDER   \n",
       "...      ...                                                ...      ...   \n",
       "26867     BL  I am waiting for a rebate of {{Refund Amount}}...   REFUND   \n",
       "26868    BIL  how to see if there is anything wrong with my ...   REFUND   \n",
       "26869   BLQZ  I'm waiting for a reimbjrsement of {{Currency ...   REFUND   \n",
       "26870     BL  I don't know what to do to see my reimbursemen...   REFUND   \n",
       "26871     BL  I need to know if there is anything new on the...   REFUND   \n",
       "\n",
       "             intent                                           response  \n",
       "0      cancel_order  I've understood you have a question regarding ...  \n",
       "1      cancel_order  I've been informed that you have a question ab...  \n",
       "2      cancel_order  I can sense that you're seeking assistance wit...  \n",
       "3      cancel_order  I understood that you need assistance with can...  \n",
       "4      cancel_order  I'm sensitive to the fact that you're facing f...  \n",
       "...             ...                                                ...  \n",
       "26867  track_refund  Thank you for sharing your situation regarding...  \n",
       "26868  track_refund  Ensuring the accuracy of your restitution is o...  \n",
       "26869  track_refund  Firstly, I genuinely understand the importance...  \n",
       "26870  track_refund  I've understood you're unsure about how to che...  \n",
       "26871  track_refund  It's completely understandable that you want t...  \n",
       "\n",
       "[26872 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.DataFrame(ds['train'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "ACCOUNT         5986\n",
       "ORDER           3988\n",
       "REFUND          2992\n",
       "INVOICE         1999\n",
       "CONTACT         1999\n",
       "PAYMENT         1998\n",
       "FEEDBACK        1997\n",
       "DELIVERY        1994\n",
       "SHIPPING        1970\n",
       "SUBSCRIPTION     999\n",
       "CANCEL           950\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have to check how soon can I expect the purc...</td>\n",
       "      <td>How should I address this delivery-related que...</td>\n",
       "      <td>We understand your anticipation to know the es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>locate bill{{Invoice Number}}</td>\n",
       "      <td>How should I assist with this invoice-related ...</td>\n",
       "      <td>Assuredly! I understand your need to locate th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>need assistance to obtain a refund of money</td>\n",
       "      <td>What's the proper way to handle this refund re...</td>\n",
       "      <td>I appreciate that you require assistance in ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I don't know how I can talk to cstomer support</td>\n",
       "      <td>What's the best way to guide the customer to c...</td>\n",
       "      <td>Grateful for your contact! I get the sense tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>help editing purchase {{Order Number}}</td>\n",
       "      <td>How should I address this order-related inquir...</td>\n",
       "      <td>We understand that you need assistance with ed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  I have to check how soon can I expect the purc...   \n",
       "1                      locate bill{{Invoice Number}}   \n",
       "2        need assistance to obtain a refund of money   \n",
       "3     I don't know how I can talk to cstomer support   \n",
       "4             help editing purchase {{Order Number}}   \n",
       "\n",
       "                                            question  \\\n",
       "0  How should I address this delivery-related que...   \n",
       "1  How should I assist with this invoice-related ...   \n",
       "2  What's the proper way to handle this refund re...   \n",
       "3  What's the best way to guide the customer to c...   \n",
       "4  How should I address this order-related inquir...   \n",
       "\n",
       "                                              answer  \n",
       "0  We understand your anticipation to know the es...  \n",
       "1  Assuredly! I understand your need to locate th...  \n",
       "2  I appreciate that you require assistance in ob...  \n",
       "3  Grateful for your contact! I get the sense tha...  \n",
       "4  We understand that you need assistance with ed...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to generate context, question, and answer from the dataset\n",
    "def prepare_data(data):\n",
    "    contexts = data['instruction'].tolist()\n",
    "    questions = []\n",
    "    answers = data['response'].tolist()\n",
    "\n",
    "    # Generate questions based on the category and intent of each row\n",
    "    for instruction, category, intent in zip(data['instruction'], data['category'], data['intent']):\n",
    "        if category == \"ACCOUNT\":\n",
    "            questions.append(f\"How should I handle this account-related request: '{instruction}'?\")\n",
    "        elif category == \"ORDER\":\n",
    "            if \"cancel\" in intent.lower():\n",
    "                questions.append(f\"What's the appropriate response to cancel an order: '{instruction}'?\")\n",
    "            else:\n",
    "                questions.append(f\"How should I address this order-related inquiry: '{instruction}'?\")\n",
    "        elif category == \"REFUND\":\n",
    "            questions.append(f\"What's the proper way to handle this refund request: '{instruction}'?\")\n",
    "        elif category == \"INVOICE\":\n",
    "            questions.append(f\"How should I assist with this invoice-related query: '{instruction}'?\")\n",
    "        elif category == \"CONTACT\":\n",
    "            questions.append(f\"What's the best way to guide the customer to contact support given: '{instruction}'?\")\n",
    "        elif category == \"PAYMENT\":\n",
    "            questions.append(f\"How should I respond to this payment-related inquiry: '{instruction}'?\")\n",
    "        elif category == \"FEEDBACK\":\n",
    "            questions.append(f\"What's an appropriate response to this feedback: '{instruction}'?\")\n",
    "        elif category == \"DELIVERY\":\n",
    "            questions.append(f\"How should I address this delivery-related question: '{instruction}'?\")\n",
    "        elif category == \"SHIPPING\":\n",
    "            questions.append(f\"What's the proper response to this shipping inquiry: '{instruction}'?\")\n",
    "        elif category == \"SUBSCRIPTION\":\n",
    "            questions.append(f\"How do I handle this subscription-related request: '{instruction}'?\")\n",
    "        elif category == \"CANCEL\":\n",
    "            questions.append(f\"What's the appropriate way to process this cancellation request: '{instruction}'?\")\n",
    "        else:\n",
    "            questions.append(f\"How should I respond to this request: '{instruction}'?\")\n",
    "    \n",
    "    return contexts, questions, answers\n",
    "\n",
    "# Prepare the data\n",
    "contexts, questions, answers = prepare_data(data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_contexts, test_contexts, train_questions, test_questions, train_answers, test_answers = train_test_split(\n",
    "    contexts, questions, answers, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Create a DataFrame for the training and testing sets\n",
    "train = pd.DataFrame({\"context\": train_contexts, \"question\": train_questions, \"answer\": train_answers})\n",
    "test = pd.DataFrame({\"context\": test_contexts, \"question\": test_questions, \"answer\": test_answers})\n",
    "\n",
    "# Display the first few rows of the training set\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input shape: torch.Size([24184, 512])\n",
      "Testing input shape: torch.Size([2688, 512])\n"
     ]
    }
   ],
   "source": [
    "# Next steps our fine tuning our BERT \n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to tokenize the data for BERT QA\n",
    "def tokenize_data(contexts, questions, answers, max_length=512):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    \n",
    "    for context, question, answer in zip(contexts, questions, answers):\n",
    "        # Encode the context and question using the tokenizer\n",
    "        encoding = tokenizer.encode_plus(\n",
    "            question,                      # The question\n",
    "            context,                       # The context (input text)\n",
    "            max_length=max_length,         # Maximum input length for BERT\n",
    "            padding='max_length',          # Pad input sequences to the max length\n",
    "            truncation=True,               # Truncate input sequences to the max length\n",
    "            return_attention_mask=True,    # Return attention masks\n",
    "            return_tensors='pt'            # Return PyTorch tensors\n",
    "        )\n",
    "\n",
    "        # Append the encoded inputs and attention masks\n",
    "        input_ids.append(encoding['input_ids'])\n",
    "        attention_masks.append(encoding['attention_mask'])\n",
    "\n",
    "        # Find the start and end positions of the answer within the context\n",
    "        start_idx = context.find(answer)\n",
    "        end_idx = start_idx + len(answer) - 1\n",
    "\n",
    "        # Append the start and end positions\n",
    "        start_positions.append(start_idx)\n",
    "        end_positions.append(end_idx)\n",
    "    \n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    start_positions = torch.tensor(start_positions)\n",
    "    end_positions = torch.tensor(end_positions)\n",
    "    \n",
    "    return input_ids, attention_masks, start_positions, end_positions\n",
    "\n",
    "# Tokenize the training data\n",
    "train_input_ids, train_attention_masks, train_start_positions, train_end_positions = tokenize_data(\n",
    "    train['context'].tolist(), \n",
    "    train['question'].tolist(), \n",
    "    train['answer'].tolist()\n",
    ")\n",
    "\n",
    "# Tokenize the testing data\n",
    "test_input_ids, test_attention_masks, test_start_positions, test_end_positions = tokenize_data(\n",
    "    test['context'].tolist(), \n",
    "    test['question'].tolist(), \n",
    "    test['answer'].tolist()\n",
    ")\n",
    "\n",
    "# Check the shape of the tokenized data\n",
    "print(f\"Training input shape: {train_input_ids.shape}\")\n",
    "print(f\"Testing input shape: {test_input_ids.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 101, 2054, 1005,  ...,    0,    0,    0],\n",
      "        [ 101, 2129, 2323,  ...,    0,    0,    0],\n",
      "        [ 101, 2129, 2323,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2054, 1005,  ...,    0,    0,    0],\n",
      "        [ 101, 2129, 2323,  ...,    0,    0,    0],\n",
      "        [ 101, 2054, 1005,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]), tensor([ 850,  981,  315,  397,  504,  652,  472, 1264,  593,  581,  642,  459,\n",
      "         788,  299,  350,  292])]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Create TensorDataset for training and testing data\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_start_positions, train_end_positions)\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_start_positions, test_end_positions)\n",
    "\n",
    "# Create DataLoader for the training and testing sets\n",
    "batch_size = 16\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)\n",
    "\n",
    "# Check if DataLoader is working\n",
    "for batch in train_dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\imaad\\anaconda3\\envs\\healthenv\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Step 0, Loss: 6.205663681030273\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 30\u001b[0m\n\u001b[0;32m     26\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, \n\u001b[0;32m     27\u001b[0m                 start_positions\u001b[38;5;241m=\u001b[39mstart_positions, end_positions\u001b[38;5;241m=\u001b[39mend_positions)\n\u001b[0;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m---> 30\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# Update the model parameters\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\imaad\\anaconda3\\envs\\healthenv\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\imaad\\anaconda3\\envs\\healthenv\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import BertForQuestionAnswering, AdamW\n",
    "\n",
    "# Load the BERT QA model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Fine-tuning loop\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    \n",
    "    # Training loop\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        input_ids, attention_mask, start_positions, end_positions = batch\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                        start_positions=start_positions, end_positions=end_positions)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        \n",
    "        optimizer.step()  # Update the model parameters\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}, Loss: {loss.item()}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"bert-qa-finetuned\")\n",
    "tokenizer.save_pretrained(\"bert-qa-finetuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "healthenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
